{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle - CHAMPS - submission.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "td7FAK3QVbKU",
        "1VE6L1DEcde9",
        "shg5noYpA6dN",
        "g_ghtZ7F140B"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td7FAK3QVbKU",
        "colab_type": "text"
      },
      "source": [
        "## Import Kaggle datasets into Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZU47ILVj4Xn",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oldWLHK8tRSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6Gdp8oDBKeF",
        "colab_type": "text"
      },
      "source": [
        "Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5yaOr59H2ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRRyI2hb-nnf",
        "colab_type": "text"
      },
      "source": [
        "Run the following code cell to change current working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE5Z9XBl8ZGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd drive\n",
        "%cd 'My Drive'\n",
        "%cd CHAMPS_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGWo7Z1a_Fgf",
        "colab_type": "text"
      },
      "source": [
        "Use Kaggle API to download CHAMPS dataset - **Only run if dataset isn't already established in your Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogKdJRwoIZMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"abasu89\"\n",
        "os.environ['KAGGLE_KEY'] = \"043fae37443c24fe3c56f2018a03e69f\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfncR_1eJ2ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c champs-scalar-coupling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zjt41_jrjuN8",
        "colab_type": "text"
      },
      "source": [
        "Run the following code block for all zipped data files (resulting from the download performed in the above code cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCbmpmrjNUmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_ref = zipfile.ZipFile('train.csv.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE8VTHlQVVr3",
        "colab_type": "text"
      },
      "source": [
        "## Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Qo_Vh4C-1Q",
        "colab_type": "text"
      },
      "source": [
        "### Assign datasets to variables\n",
        "\n",
        "This section should **always** be executed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7Hv1HGtCmzz",
        "colab_type": "text"
      },
      "source": [
        "Import necessary packages and print files present in current directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9OgbDiRQPWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "%matplotlib inline\n",
        "\n",
        "print(os.listdir())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y0xwJi9k6Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = pd.read_csv(\"train.csv\")\n",
        "scalar_coupling_ctbs = pd.read_csv(\"scalar_coupling_contributions.csv\")\n",
        "dipole_moments = pd.read_csv(\"dipole_moments.csv\")\n",
        "magnetic_shld_ts = pd.read_csv(\"magnetic_shielding_tensors.csv\")\n",
        "mulliken_charge = pd.read_csv(\"mulliken_charges.csv\")\n",
        "potential_energy = pd.read_csv(\"potential_energy.csv\")\n",
        "structures = pd.read_csv(\"structures.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg1-wVYhlBeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ds = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0w8Gpz0DIlB",
        "colab_type": "text"
      },
      "source": [
        "### Combine datasets\n",
        "\n",
        "Code in this section only needs to be executed if the Data Visualization section in this notebook is being used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxDEogdclT0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('concatenating scalar coupling contributions with train_ds...')\n",
        "combined_data = pd.concat([train_ds, scalar_coupling_ctbs[['fc','sd','pso','dso']]], axis=1) # merge these 4 columns from scalar_coupling_ctbs into train_ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8x9UBP65_K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('concatenating structures with train_ds...')\n",
        "x = combined_data.merge(structures, right_on=['molecule_name', 'atom_index'], left_on=['molecule_name', 'atom_index_1'])\n",
        "combined_data = x.merge(structures, right_on=['molecule_name', 'atom_index'], left_on=['molecule_name', 'atom_index_0'], suffixes=('_atom_1','_atom_0'))\n",
        "combined_data.drop(['atom_index_atom_0', 'atom_index_atom_1'], axis=1, inplace=True) # remove redundant columns\n",
        "arrange_cols = ['id', 'molecule_name', 'type', 'atom_index_0', 'atom_atom_0', 'x_atom_0', 'y_atom_0', 'z_atom_0', 'atom_index_1', 'atom_atom_1', 'x_atom_1', 'y_atom_1', 'z_atom_1', 'fc',\n",
        "                'sd','pso','dso','scalar_coupling_constant']\n",
        "combined_data = combined_data[arrange_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsjRz6BulZ_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('merging structures with test_ds...')\n",
        "y = test_ds.merge(structures, right_on=['molecule_name', 'atom_index'], left_on=['molecule_name', 'atom_index_1'])\n",
        "test_dataset = y.merge(structures, right_on=['molecule_name', 'atom_index'], left_on=['molecule_name', 'atom_index_0'], suffixes=('_atom_1', '_atom_0'))\n",
        "test_dataset.drop(['atom_index_atom_0','atom_index_atom_1'], axis=1, inplace=True)\n",
        "test_arrange_cols = ['id', 'molecule_name', 'type','atom_index_0', 'atom_atom_0', 'x_atom_0', 'y_atom_0', 'z_atom_0', 'atom_index_1', 'atom_atom_1', 'x_atom_1', 'y_atom_1', 'z_atom_1']\n",
        "test_dataset = test_dataset[test_arrange_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZfZudCXlcx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('merging magnetic_shield_tensors with combined_data...')\n",
        "x = combined_data.merge(magnetic_shld_ts, right_on=['molecule_name', 'atom_index'], left_on=['molecule_name', 'atom_index_1'])\n",
        "combined_data = x.merge(magnetic_shld_ts, right_on=['molecule_name', 'atom_index'], left_on=['molecule_name', 'atom_index_0'], suffixes=('_atom_1', '_atom_0'))\n",
        "combined_data.drop(['atom_index_atom_0',  'atom_index_atom_1'], axis=1, inplace=True)\n",
        "arrange_cols = ['id', 'molecule_name', 'type','atom_index_0', 'atom_atom_0', 'x_atom_0', 'y_atom_0', 'z_atom_0',  'XX_atom_0', 'YX_atom_0', 'ZX_atom_0', 'XY_atom_0', 'YY_atom_0', \n",
        "                'ZY_atom_0', 'XZ_atom_0', 'YZ_atom_0', 'ZZ_atom_0','atom_index_1', 'atom_atom_1', 'x_atom_1', 'y_atom_1', 'z_atom_1', 'XX_atom_1', 'YX_atom_1', 'ZX_atom_1', 'XY_atom_1', \n",
        "                'YY_atom_1', 'ZY_atom_1', 'XZ_atom_1', 'YZ_atom_1', 'ZZ_atom_1','fc', 'sd', 'pso', 'dso', 'scalar_coupling_constant']\n",
        "combined_data = combined_data[arrange_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoxO3Wkplfht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('merging mulliken_charge with combined_data...')\n",
        "x = combined_data.merge(mulliken_charge, right_on=['molecule_name', 'atom_index'], left_on=['molecule_name', 'atom_index_1'])\n",
        "combined_data = x.merge(mulliken_charge, right_on=['molecule_name', 'atom_index'], left_on=['molecule_name', 'atom_index_0'], suffixes=('_atom_1', '_atom_0'))\n",
        "combined_data.drop(['atom_index_atom_0',  'atom_index_atom_1'], axis=1, inplace=True)\n",
        "arrange_cols = ['id', 'molecule_name', 'type', 'atom_index_0', 'atom_atom_0', 'x_atom_0', 'y_atom_0', 'z_atom_0',  'XX_atom_0', 'YX_atom_0', 'ZX_atom_0', 'XY_atom_0', 'YY_atom_0', \n",
        "                'ZY_atom_0', 'XZ_atom_0', 'YZ_atom_0', 'ZZ_atom_0','mulliken_charge_atom_0','atom_index_1', 'atom_atom_1', 'x_atom_1', 'y_atom_1', 'z_atom_1', 'XX_atom_1', 'YX_atom_1', \n",
        "                'ZX_atom_1', 'XY_atom_1', 'YY_atom_1', 'ZY_atom_1', 'XZ_atom_1', 'YZ_atom_1', 'ZZ_atom_1','mulliken_charge_atom_1','fc', 'sd', 'pso', 'dso', 'scalar_coupling_constant']\n",
        "combined_data = combined_data[arrange_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgbfH1gpliBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('merging dipole moments with combined_data...')\n",
        "combined_data = combined_data.merge(dipole_moments, right_on='molecule_name', left_on='molecule_name')\n",
        "arrange_cols = ['id', 'molecule_name', 'type', 'X', 'Y', 'Z','atom_index_0', 'atom_atom_0', 'x_atom_0', 'y_atom_0', 'z_atom_0','XX_atom_0', 'YX_atom_0', 'ZX_atom_0', 'XY_atom_0', \n",
        "                'YY_atom_0', 'ZY_atom_0', 'XZ_atom_0', 'YZ_atom_0', 'ZZ_atom_0','mulliken_charge_atom_0','atom_index_1', 'atom_atom_1', 'x_atom_1', 'y_atom_1', 'z_atom_1', 'XX_atom_1', \n",
        "                'YX_atom_1', 'ZX_atom_1', 'XY_atom_1', 'YY_atom_1', 'ZY_atom_1', 'XZ_atom_1', 'YZ_atom_1', 'ZZ_atom_1','mulliken_charge_atom_1','fc', 'sd', 'pso', 'dso', \n",
        "                'scalar_coupling_constant']\n",
        "combined_data = combined_data[arrange_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJqRc56_lkem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('merging potential_energy with combined_data...')\n",
        "combined_data = combined_data.merge(potential_energy, right_on='molecule_name', left_on='molecule_name')\n",
        "arrange_cols = ['id', 'molecule_name', 'type', 'X', 'Y', 'Z', 'potential_energy','atom_index_0', 'atom_atom_0', 'x_atom_0', 'y_atom_0', 'z_atom_0','XX_atom_0', 'YX_atom_0', 'ZX_atom_0', \n",
        "                'XY_atom_0', 'YY_atom_0', 'ZY_atom_0', 'XZ_atom_0', 'YZ_atom_0', 'ZZ_atom_0','mulliken_charge_atom_0','atom_index_1', 'atom_atom_1', 'x_atom_1', 'y_atom_1', 'z_atom_1', \n",
        "                'XX_atom_1', 'YX_atom_1', 'ZX_atom_1', 'XY_atom_1', 'YY_atom_1', 'ZY_atom_1', 'XZ_atom_1', 'YZ_atom_1', 'ZZ_atom_1','mulliken_charge_atom_1','fc', 'sd', 'pso', 'dso', \n",
        "                'scalar_coupling_constant']\n",
        "combined_data = combined_data[arrange_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9z4ZK1_Ejyh",
        "colab_type": "text"
      },
      "source": [
        "Check for missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C4Q0aAQloMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_data.columns[combined_data.isna().any()].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9nMCl0mEocb",
        "colab_type": "text"
      },
      "source": [
        "One-hot encode categorical variables in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-nmlOVzlr97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = pd.get_dummies(combined_data['type'])\n",
        "combined_data = combined_data.drop('type', axis=1)\n",
        "combined_data = combined_data.join(enc)\n",
        "\n",
        "enc2 = pd.get_dummies(combined_data['atom_atom_0'])\n",
        "combined_data = combined_data.drop('atom_atom_0', axis=1)\n",
        "combined_data = combined_data.join(enc2, rsuffix='_atom_0')\n",
        "combined_data = combined_data.rename(index=str, columns={\"H\": \"H_atom_0\"})\n",
        "\n",
        "enc3 = pd.get_dummies(combined_data['atom_atom_1'])\n",
        "combined_data = combined_data.drop('atom_atom_1', axis=1)\n",
        "combined_data = combined_data.join(enc3, rsuffix='_atom_1')\n",
        "combined_data = combined_data.rename(index=str, columns={\"C\": 'C_atom_1', \"N\": \"N_atom_1\", 'H':'H_atom_1'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSmhb_2EE1dx",
        "colab_type": "text"
      },
      "source": [
        "One-hot encode categorical variables in the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e4IsCrFBej1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_test = pd.get_dummies(test_dataset['type'])\n",
        "test_dataset = test_dataset.drop('type', axis=1)\n",
        "test_dataset = test_dataset.join(enc)\n",
        "\n",
        "enc2_test = pd.get_dummies(test_dataset['atom_atom_0'])\n",
        "test_dataset = test_dataset.drop('atom_atom_0', axis=1)\n",
        "test_dataset = test_dataset.join(enc2, rsuffix='_atom_0')\n",
        "test_dataset = test_dataset.rename(index=str, columns={\"H\": \"H_atom_0\"})\n",
        "\n",
        "enc3_test = pd.get_dummies(test_dataset['atom_atom_1'])\n",
        "test_dataset = test_dataset.drop('atom_atom_1', axis=1)\n",
        "test_dataset = test_dataset.join(enc3, rsuffix='_atom_1')\n",
        "test_dataset = test_dataset.rename(index=str, columns={\"C\": 'C_atom_1', \"N\": \"N_atom_1\", 'H':'H_atom_1'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2CBvcbfGLnK",
        "colab_type": "text"
      },
      "source": [
        "Split training set into dependent and independent variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inQFVSBEl1rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scc_target = combined_data['scalar_coupling_constant'].as_matrix()\n",
        "combined_data = combined_data.drop('scalar_coupling_constant', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_94cQQYeFBeC",
        "colab_type": "text"
      },
      "source": [
        "Check columns present in training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXoDGIbRAiNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T40eHtj_Al5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSSuTC55U4o2",
        "colab_type": "text"
      },
      "source": [
        "# **Data Visualizations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4FGEPr_GQ2t",
        "colab_type": "text"
      },
      "source": [
        "## Exploring the Input Space\n",
        "The code in this section was adapted from the following Kaggle kernel: https://www.kaggle.com/robikscube/exploring-molecular-properties-data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_o_J04MGTLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "plt.style.use('ggplot')\n",
        "color_pal = [x['color'] for x in plt.rcParams['axes.prop_cycle']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPnVzHVKGzyK",
        "colab_type": "text"
      },
      "source": [
        "Distribution of the target variable in the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs75H8IyGjSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds['scalar_coupling_constant'].plot(kind='hist', figsize=(20, 5), bins=1000, title=\"Distribution of target variable\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHCCEqCuHsKn",
        "colab_type": "text"
      },
      "source": [
        "Number of atom pairs in molecules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxh0Wbi2IzEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(1,2)\n",
        "train_ds.groupby('molecule_name').count().sort_values('id')['id'].plot(kind='hist', bins=25, color=color_pal[6], figsize=(20,5), title='# of Atom Pairs in Molecules in Training Set', ax=ax[0])\n",
        "test_ds.groupby('molecule_name').count().sort_values('id')['id'].plot(kind='hist', bins=25, color=color_pal[2], figsize=(20,5), title='# of Atom Pairs in Molecules in Test Set', ax=ax[1])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9HjTZsVPFY7",
        "colab_type": "text"
      },
      "source": [
        "Distribution of Mulliken Charges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwpQKxegPH9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mulliken_charge['mulliken_charge'].plot(kind='hist', figsize=(15, 5), bins=500, title='Distribution of Mulliken Charges')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e_iKGTrPhtk",
        "colab_type": "text"
      },
      "source": [
        "Distribution of Potential Energy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIrtXXoEPOpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "potential_energy['potential_energy'].plot(kind='hist',figsize=(15, 5), bins=500, title='Distribution of Potential Energy', color='b')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDiUTtXVP2D0",
        "colab_type": "text"
      },
      "source": [
        "Coupling Type Count in Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGMCetSLP69w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scalar_coupling_ctbs.groupby('type').count()['molecule_name'].sort_values().plot(kind='barh', color='grey', figsize=(15,5), title='Coupling Type Count in Training Set')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afeN059bQiRC",
        "colab_type": "text"
      },
      "source": [
        "Distribution of Scalar Coupling Contributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BT2MSjlQm_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(2, 2, figsize=(20,10))\n",
        "scalar_coupling_ctbs['fc'].plot(kind='hist', ax=ax.flat[0], bins=500, title='Fermi Contact contribution', color=color_pal[0])\n",
        "scalar_coupling_ctbs['sd'].plot(kind='hist', ax=ax.flat[1], bins=500, title='Spin-dipolar contribution', color=color_pal[1])\n",
        "scalar_coupling_ctbs['pso'].plot(kind='hist', ax=ax.flat[2], bins=500, title='Paramagnetic spin-orbit contribution', color=color_pal[2])\n",
        "scalar_coupling_ctbs['dso'].plot(kind='hist', ax=ax.flat[3], bins=500, title='Diamagnetic spin-orbit contribution', color=color_pal[3])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3htZJ796MieB",
        "colab_type": "text"
      },
      "source": [
        "## Free Form Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF0-O5xsNTce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "example = structures.loc[structures['molecule_name'] == 'dsgdb9nsd_000011']\n",
        "ax.scatter(xs=example['x'], ys=example['y'], zs=example['z'], s=100)\n",
        "plt.suptitle('dsgdb9nsd_000011')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS2eW4ZcSbQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "example = structures.loc[structures['molecule_name'] == 'dsgdb9nsd_000010']\n",
        "ax.scatter(xs=example['x'], ys=example['y'], zs=example['z'], s=100)\n",
        "plt.suptitle('dsgdb9nsd_000010')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4DTp5I_VIEo",
        "colab_type": "text"
      },
      "source": [
        "## Visualisations using Matplotlib\n",
        "This section uses the Matplotlib package to perform visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uQh0B6TLN1o",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots scalar coupling constant contributions (fc, sd, pso, dso) against the scalar coupling constant (target variable)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xoIWqbyl-iT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (10,5))\n",
        "plt.subplot(2,2,1)\n",
        "plt.scatter(combined_data['fc'], scc_target)\n",
        "plt.title('fc vs scalar coupling constant')\n",
        "plt.subplot(2,2,2)\n",
        "plt.scatter(combined_data['sd'], scc_target)\n",
        "plt.title('sd vs scalar coupling constant')\n",
        "plt.subplot(2,2,3)\n",
        "plt.scatter(combined_data['pso'], scc_target)\n",
        "plt.title('pso vs scalar coupling constant')\n",
        "plt.subplot(2,2,4)\n",
        "plt.scatter(combined_data['dso'], scc_target)\n",
        "plt.title('dso vs scalar coupling constant')\n",
        "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25, wspace=0.35)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0HV-rn3LsC6",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots fc vs target variable for each coupling type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD87NIjowBNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.merge(train_ds, scalar_coupling_ctbs, how = 'left',\n",
        "                  left_on  = ['molecule_name', 'atom_index_0', 'atom_index_1', 'type'],\n",
        "                  right_on = ['molecule_name', 'atom_index_0', 'atom_index_1', 'type'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (20, 10))      \n",
        "for i, t in enumerate(train['type'].unique()):\n",
        "    plt.subplot(2, 4, i + 1);\n",
        "    plt.scatter(train.loc[train['type'] == t, 'fc'], \n",
        "                train.loc[train['type'] == t, 'scalar_coupling_constant'], label=t);\n",
        "    plt.title(f'fc vs target \\n for {t} type');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0mBrvEzMWkz",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots sd vs target variable for each coupling type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdZ25r2dGmiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (20, 10))      \n",
        "for i, t in enumerate(train['type'].unique()):\n",
        "    plt.subplot(2, 4, i + 1);\n",
        "    plt.scatter(train.loc[train['type'] == t, 'sd'], \n",
        "                train.loc[train['type'] == t, 'scalar_coupling_constant'], label=t);\n",
        "    plt.title(f'sd vs target \\n for {t} type');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAnbf6_mMZ2J",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots pso vs target variable for each coupling type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y_3WHks2UUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (20, 10))      \n",
        "for i, t in enumerate(train['type'].unique()):\n",
        "    plt.subplot(2, 4, i + 1);\n",
        "    plt.scatter(train.loc[train['type'] == t, 'pso'], \n",
        "                train.loc[train['type'] == t, 'scalar_coupling_constant'], label=t);\n",
        "    plt.title(f'pso vs target \\n for {t} type');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EU8z5OKMdWs",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots dso vs target variable for each coupling type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmjEO9jIG_F8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (20, 10))      \n",
        "for i, t in enumerate(train['type'].unique()):\n",
        "    plt.subplot(2, 4, i + 1);\n",
        "    plt.scatter(train.loc[train['type'] == t, 'dso'], \n",
        "                train.loc[train['type'] == t, 'scalar_coupling_constant'], label=t);\n",
        "    plt.title(f'dso vs target \\n for {t} type');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR4109ifMl__",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots the magnetic shielding tensors vs target variable for Atom 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlIAy5GUHsJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (20,10))\n",
        "plt.subplot(3,3,1)\n",
        "plt.scatter(combined_data['XX_atom_0'], scc_target)\n",
        "plt.title('XX_atom_0 vs target')\n",
        "plt.subplot(3,3,2)\n",
        "plt.scatter(combined_data['YX_atom_0'], scc_target)\n",
        "plt.title('YX_atom_0 vs target')\n",
        "plt.subplot(3,3,3)\n",
        "plt.scatter(combined_data['ZX_atom_0'], scc_target)\n",
        "plt.title('ZX_atom_0 vs target')\n",
        "plt.subplot(3,3,4)\n",
        "plt.scatter(combined_data['XY_atom_0'], scc_target)\n",
        "plt.title('XY_atom_0 vs target')\n",
        "plt.subplot(3,3,5)\n",
        "plt.scatter(combined_data['YY_atom_0'], scc_target)\n",
        "plt.title('YY_atom_0 vs target')\n",
        "plt.subplot(3,3,6)\n",
        "plt.scatter(combined_data['ZY_atom_0'], scc_target)\n",
        "plt.title('ZY_atom_0 vs target')\n",
        "plt.subplot(3,3,7)\n",
        "plt.scatter(combined_data['XZ_atom_0'], scc_target)\n",
        "plt.title('XZ_atom_0 vs target')\n",
        "plt.subplot(3,3,8)\n",
        "plt.scatter(combined_data['YZ_atom_0'], scc_target)\n",
        "plt.title('YZ_atom_0 vs target')\n",
        "plt.subplot(3,3,9)\n",
        "plt.scatter(combined_data['ZZ_atom_0'], scc_target)\n",
        "plt.title('ZZ_atom_0 vs target')\n",
        "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25, wspace=0.35)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2EsgVTmNJdx",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots the magnetic shielding tensors vs target variable for Atom 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2aWcQhWLsFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (20,10))\n",
        "plt.subplot(3,3,1)\n",
        "plt.scatter(combined_data['XX_atom_1'], scc_target)\n",
        "plt.title('XX_atom_1 vs target')\n",
        "plt.subplot(3,3,2)\n",
        "plt.scatter(combined_data['YX_atom_1'], scc_target)\n",
        "plt.title('YX_atom_1 vs target')\n",
        "plt.subplot(3,3,3)\n",
        "plt.scatter(combined_data['ZX_atom_1'], scc_target)\n",
        "plt.title('ZX_atom_1 vs target')\n",
        "plt.subplot(3,3,4)\n",
        "plt.scatter(combined_data['XY_atom_1'], scc_target)\n",
        "plt.title('XY_atom_1 vs target')\n",
        "plt.subplot(3,3,5)\n",
        "plt.scatter(combined_data['YY_atom_1'], scc_target)\n",
        "plt.title('YY_atom_1 vs target')\n",
        "plt.subplot(3,3,6)\n",
        "plt.scatter(combined_data['ZY_atom_1'], scc_target)\n",
        "plt.title('ZY_atom_1 vs target')\n",
        "plt.subplot(3,3,7)\n",
        "plt.scatter(combined_data['XZ_atom_1'], scc_target)\n",
        "plt.title('XZ_atom_1 vs target')\n",
        "plt.subplot(3,3,8)\n",
        "plt.scatter(combined_data['YZ_atom_1'], scc_target)\n",
        "plt.title('YZ_atom_1 vs target')\n",
        "plt.subplot(3,3,9)\n",
        "plt.scatter(combined_data['ZZ_atom_1'], scc_target)\n",
        "plt.title('ZZ_atom_1 vs target')\n",
        "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25, wspace=0.35)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOE4BgOwNOYp",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots the mulliken charge vs target for both atoms in an atomic pair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHxeI3LwObZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (20,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(combined_data['mulliken_charge_atom_0'], scc_target)\n",
        "plt.title('mulliken_charge_atom_0 vs target')\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(combined_data['mulliken_charge_atom_1'], scc_target)\n",
        "plt.title('mulliken_charge_atom_1 vs target')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io8KTAGkNU7b",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots the dipole moment in each direction vs target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dwo-8lzP-S2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (20,10))\n",
        "plt.subplot(1,3,1)\n",
        "plt.scatter(combined_data['X'], scc_target)\n",
        "plt.title('dipole moment X vs target')\n",
        "plt.subplot(1,3,2)\n",
        "plt.scatter(combined_data['Y'], scc_target)\n",
        "plt.title('dipole moment Y vs target')\n",
        "plt.subplot(1,3,3)\n",
        "plt.scatter(combined_data['Z'], scc_target)\n",
        "plt.title('dipole moment Z vs target')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_VKsfP5NaT9",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots the molecular structure coordinates in each axis vs target variable for both atoms in an atomic couple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnImXx5fSIEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (20,10))\n",
        "plt.subplot(2,3,1)\n",
        "plt.scatter(combined_data['x_atom_0'], scc_target)\n",
        "plt.title('structure x vs target - atom 0')\n",
        "plt.subplot(2,3,2)\n",
        "plt.scatter(combined_data['y_atom_0'], scc_target)\n",
        "plt.title('structure y vs target - atom 0')\n",
        "plt.subplot(2,3,3)\n",
        "plt.scatter(combined_data['z_atom_0'], scc_target)\n",
        "plt.title('structure z vs target - atom 0')\n",
        "plt.subplot(2,3,4)\n",
        "plt.scatter(combined_data['x_atom_1'], scc_target)\n",
        "plt.title('structure x vs target - atom 1')\n",
        "plt.subplot(2,3,5)\n",
        "plt.scatter(combined_data['y_atom_1'], scc_target)\n",
        "plt.title('structure y vs target - atom 1')\n",
        "plt.subplot(2,3,6)\n",
        "plt.scatter(combined_data['z_atom_1'], scc_target)\n",
        "plt.title('structure z vs target - atom 1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcZfk-ieN9_N",
        "colab_type": "text"
      },
      "source": [
        "This code cell plots potential energy vs target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCL9bojOUxXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (10,5))\n",
        "plt.subplot(1,1,1)\n",
        "plt.scatter(combined_data['potential_energy'], scc_target)\n",
        "plt.title('potential_energy vs target')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VE6L1DEcde9",
        "colab_type": "text"
      },
      "source": [
        "## Visualisations using Seaborn\n",
        "This section uses the Seaborn package to perform visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljZGUPtMRarf",
        "colab_type": "text"
      },
      "source": [
        "This code cell uses a violin plot to visualize the spread of the X, Y, Z coordinates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ_OIesR0IB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set()\n",
        "d = combined_data[['X', 'Y', 'Z']]\n",
        "sns.violinplot(data=d, inner=\"points\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eTKIYwlS0mV",
        "colab_type": "text"
      },
      "source": [
        "This code cell uses a pair-grid representation to visualize the spread of the X, Y, Z coordinates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lvZu8Py9YhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(style=\"white\")\n",
        "\n",
        "g = sns.PairGrid(d, diag_sharey=False)\n",
        "g.map_lower(sns.kdeplot)\n",
        "g.map_upper(sns.scatterplot)\n",
        "g.map_diag(sns.kdeplot, lw=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WTq0NyEGUPn",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bh6XgRmCEm_",
        "colab_type": "text"
      },
      "source": [
        "Extract molecular structure data from `combined_data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C360OYDrA_9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainData_rf = combined_data[['atom_index_0', 'x_atom_0', 'y_atom_0',\n",
        "       'z_atom_0', 'atom_index_1', 'x_atom_1', 'y_atom_1', 'z_atom_1', '1JHC',\n",
        "       '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN', 'H_atom_0',\n",
        "       'C_atom_1', 'H_atom_1', 'N_atom_1']]\n",
        "testData_rf = test_dataset[['atom_index_0', 'x_atom_0', 'y_atom_0',\n",
        "       'z_atom_0', 'atom_index_1', 'x_atom_1', 'y_atom_1', 'z_atom_1', '1JHC',\n",
        "       '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN', 'H_atom_0',\n",
        "       'C_atom_1', 'H_atom_1', 'N_atom_1']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQwUsfQ7UUFy",
        "colab_type": "text"
      },
      "source": [
        "Split training set into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOPNX7xml7Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_split = .2 \n",
        "valid_num = int(np.shape(combined_data)[0] * valid_split)\n",
        "validSet_rf = trainData_rf.iloc[:valid_num, :]\n",
        "trainSet_rf = trainData_rf.iloc[valid_num:, :]\n",
        "valid_scc_rf = scc_target[:valid_num]\n",
        "train_scc_rf = scc_target[valid_num:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shg5noYpA6dN",
        "colab_type": "text"
      },
      "source": [
        "## [Benchmark] Random Forest using only molecular structure data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa9NDyGjGiTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnDtRIvLecxl",
        "colab_type": "text"
      },
      "source": [
        "Train on training set and perform predictions on validation set and evaluate **R^2** score based on validation set predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ72imSbCbCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = time.time()\n",
        "X, y = trainSet_rf[:50000], train_scc_rf[:50000]\n",
        "regr = RandomForestRegressor(random_state=0, n_estimators=500, criterion = 'mse')\n",
        "regr.fit(X, y) \n",
        "end = time.time()\n",
        "print ('The training time is {}'.format(start - end))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X53Ej4b8MRzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bm_score_r2 = regr.score(validSet_rf, valid_scc_rf)\n",
        "print ('The R^2 score is {}'.format(bm_score_r2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H10lLZNHBjIB",
        "colab_type": "text"
      },
      "source": [
        "Compute evaluation metric: **Log of Mean Absolute Error (MAE)** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtRr2jP4BhxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_actual = valid_scc_rf\n",
        "y_pred = regr.predict(validSet_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K35cewEINkRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_score  = np.log(mean_absolute_error(y_actual, y_pred)) / len(y_actual)\n",
        "print (\"The log of MAE is: {}\".format(eval_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhOJtobr5biK",
        "colab_type": "text"
      },
      "source": [
        "Perform predictions on test set (test.csv), submit to leaderboard to find ranking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3obdpJahVxTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(suppress='True')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaDuZsTsBA38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = regr.predict(testData_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMG0k8Qg5iAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_pred = np.array(preds).reshape(len(test_ds['id']),1)\n",
        "ids = (np.array(test_ds['id']).reshape(len(test_ds['id']),1)).astype(int)\n",
        "submission = np.hstack((ids, y_test_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2cXOWoaIV1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"predictions.csv\", submission, delimiter=\",\", header=\"id,scalar_coupling_constant\", comments='', fmt=\"%i,%f\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM5R0FAN8ofj",
        "colab_type": "text"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2R8vlCNRTOv",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network using only molecular structure data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AEsRvPpRq-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = trainData_rf.shape[1]\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYmXfxVh1-bG",
        "colab_type": "text"
      },
      "source": [
        "### Simple Neural network using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbXBTODTQPZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuEvJufJXNhD",
        "colab_type": "text"
      },
      "source": [
        "Create and compile neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmt3KX3Ud3ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NN_model = Sequential()\n",
        "# input layer\n",
        "NN_model.add(Dense(128, kernel_initializer='normal', input_dim=input_size, activation='relu'))\n",
        "# hidden layers\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "# output layer\n",
        "NN_model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
        "\n",
        "# compile network\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "NN_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6tIQ13V8Cvv",
        "colab_type": "text"
      },
      "source": [
        "Define a checkpoint callback:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB6zbbHN6Nho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5'\n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yZUYZ8r8GqH",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUP-5F0I8HcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NN_model.fit(trainSet_rf, train_scc_rf, epochs=8, batch_size=32, validation_split=0.2, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATFaO98EXVaM",
        "colab_type": "text"
      },
      "source": [
        "Load weights file of the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kdzo101FRpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_file = 'Weights-005--3.21091.hdf5' # choose the best checkpoint \n",
        "NN_model.load_weights(weights_file) # load it\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9o8m2FeXhxo",
        "colab_type": "text"
      },
      "source": [
        "Perform predictions on test set and and save to file for submission to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqkrHPNZ9x6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# perform predictions on test set\n",
        "preds = NN_model.predict(testData_rf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoHExFfEBh1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(suppress='True')\n",
        "y_test_pred = np.array(preds).reshape(len(test_ds['id']),1)\n",
        "ids = (np.array(test_ds['id']).reshape(len(test_ds['id']),1)).astype(int)\n",
        "submission = np.hstack((ids, y_test_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXMUz54dBrCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"predictions_NN-8HL.csv\", submission, delimiter=\",\", header=\"id,scalar_coupling_constant\", comments='', fmt=\"%i,%f\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee2XZNu8c-G8",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network using Newly Engineered Features\n",
        "\n",
        "Code in this section has been adapted from the following Kaggle kernel: \n",
        "https://www.kaggle.com/todnewman/keras-neural-net-for-champs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MuWhbXedKJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Input, Activation\n",
        "from keras.layers import BatchNormalization,Add,Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model, load_model\n",
        "from keras import callbacks\n",
        "from keras import backend as K\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(action=\"ignore\",category=DeprecationWarning)\n",
        "warnings.filterwarnings(action=\"ignore\",category=FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UmKMiazk-Wr",
        "colab_type": "text"
      },
      "source": [
        "Reassign variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So510J18kWTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = train_ds\n",
        "df_test = test_ds\n",
        "df_struct = structures\n",
        "df_train_sub_charge = mulliken_charge\n",
        "df_train_sub_tensor = magnetic_shld_ts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tse-qEP2rY4D",
        "colab_type": "text"
      },
      "source": [
        "This code cell reduces memory usage such that smaller cloud instances, such as Google Colab, can run the kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNJUzS8yg7eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n",
        "    \n",
        "print(df_train.shape, df_test.shape, df_struct.shape, df_train_sub_charge.shape, df_train_sub_tensor.shape)\n",
        "print(df_train.shape, df_test.shape, df_struct.shape, df_train_sub_charge.shape, df_train_sub_tensor.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyQEKwschmD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import psutil\n",
        "import os\n",
        "\n",
        "def map_atom_info(df_1,df_2, atom_idx):\n",
        "    print('Mapping...', df_1.shape, df_2.shape, atom_idx)\n",
        "    \n",
        "    df = pd.merge(df_1, df_2.drop_duplicates(subset=['molecule_name', 'atom_index']), how = 'left',\n",
        "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
        "                  right_on = ['molecule_name',  'atom_index'])\n",
        "    \n",
        "    df = df.drop('atom_index', axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "def show_ram_usage():\n",
        "    py = psutil.Process(os.getpid())\n",
        "    print('RAM usage: {} GB'.format(py.memory_info()[0]/2. ** 30))\n",
        "\n",
        "show_ram_usage()\n",
        "\n",
        "for atom_idx in [0,1]:\n",
        "    df_train = map_atom_info(df_train,df_struct, atom_idx)\n",
        "    df_train = map_atom_info(df_train,df_train_sub_charge, atom_idx)\n",
        "    df_train = map_atom_info(df_train,df_train_sub_tensor, atom_idx)\n",
        "    df_train = df_train.rename(columns={'atom': f'atom_{atom_idx}',\n",
        "                                        'x': f'x_{atom_idx}',\n",
        "                                        'y': f'y_{atom_idx}',\n",
        "                                        'z': f'z_{atom_idx}',\n",
        "                                        'mulliken_charge': f'charge_{atom_idx}',\n",
        "                                        'XX': f'XX_{atom_idx}',\n",
        "                                        'YX': f'YX_{atom_idx}',\n",
        "                                        'ZX': f'ZX_{atom_idx}',\n",
        "                                        'XY': f'XY_{atom_idx}',\n",
        "                                        'YY': f'YY_{atom_idx}',\n",
        "                                        'ZY': f'ZY_{atom_idx}',\n",
        "                                        'XZ': f'XZ_{atom_idx}',\n",
        "                                        'YZ': f'YZ_{atom_idx}',\n",
        "                                        'ZZ': f'ZZ_{atom_idx}',})\n",
        "    df_test = map_atom_info(df_test,df_struct, atom_idx)\n",
        "    df_test = df_test.rename(columns={'atom': f'atom_{atom_idx}',\n",
        "                                'x': f'x_{atom_idx}',\n",
        "                                'y': f'y_{atom_idx}',\n",
        "                                'z': f'z_{atom_idx}'})\n",
        "    #add some features\n",
        "    df_struct['c_x']=df_struct.groupby('molecule_name')['x'].transform('mean')\n",
        "    df_struct['c_y']=df_struct.groupby('molecule_name')['y'].transform('mean')\n",
        "    df_struct['c_z']=df_struct.groupby('molecule_name')['z'].transform('mean')\n",
        "    df_struct['atom_n']=df_struct.groupby('molecule_name')['atom_index'].transform('max')\n",
        "    \n",
        "    show_ram_usage()\n",
        "    print(df_train.shape, df_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NR5plOkhvsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_features(df):\n",
        "    df['dx']=df['x_1']-df['x_0']\n",
        "    df['dy']=df['y_1']-df['y_0']\n",
        "    df['dz']=df['z_1']-df['z_0']\n",
        "    df['distance']=(df['dx']**2+df['dy']**2+df['dz']**2)**(1/2)\n",
        "    return df\n",
        "\n",
        "df_train=make_features(df_train)\n",
        "df_test=make_features(df_test) \n",
        "test_prediction=np.zeros(len(df_test))\n",
        "show_ram_usage()\n",
        "print(df_train.shape, df_test.shape)\n",
        "\n",
        "def get_dist(df):\n",
        "    df_temp=df.loc[:,[\"molecule_name\",\"atom_index_0\",\"atom_index_1\",\"distance\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\"]].copy()\n",
        "    df_temp_=df_temp.copy()\n",
        "    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1',\n",
        "                                       'atom_index_1': 'atom_index_0',\n",
        "                                       'x_0': 'x_1',\n",
        "                                       'y_0': 'y_1',\n",
        "                                       'z_0': 'z_1',\n",
        "                                       'x_1': 'x_0',\n",
        "                                       'y_1': 'y_0',\n",
        "                                       'z_1': 'z_0'})\n",
        "    df_temp_all=pd.concat((df_temp,df_temp_),axis=0)\n",
        "\n",
        "    df_temp_all[\"min_distance\"]=df_temp_all.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('min')\n",
        "    df_temp_all[\"max_distance\"]=df_temp_all.groupby(['molecule_name', 'atom_index_0'])['distance'].transform('max')\n",
        "    \n",
        "    df_temp= df_temp_all[df_temp_all[\"min_distance\"]==df_temp_all[\"distance\"]].copy()\n",
        "    df_temp=df_temp.drop(['x_0','y_0','z_0','min_distance'], axis=1)\n",
        "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
        "                                         'atom_index_1': 'atom_index_closest',\n",
        "                                         'distance': 'distance_closest',\n",
        "                                         'x_1': 'x_closest',\n",
        "                                         'y_1': 'y_closest',\n",
        "                                         'z_1': 'z_closest'})\n",
        "    \n",
        "    for atom_idx in [0,1]:\n",
        "        df = map_atom_info(df,df_temp, atom_idx)\n",
        "        df = df.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n",
        "                                        'distance_closest': f'distance_closest_{atom_idx}',\n",
        "                                        'x_closest': f'x_closest_{atom_idx}',\n",
        "                                        'y_closest': f'y_closest_{atom_idx}',\n",
        "                                        'z_closest': f'z_closest_{atom_idx}'})\n",
        "        \n",
        "    df_temp= df_temp_all[df_temp_all[\"max_distance\"]==df_temp_all[\"distance\"]].copy()\n",
        "    df_temp=df_temp.drop(['x_0','y_0','z_0','max_distance'], axis=1)\n",
        "    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n",
        "                                         'atom_index_1': 'atom_index_farthest',\n",
        "                                         'distance': 'distance_farthest',\n",
        "                                         'x_1': 'x_farthest',\n",
        "                                         'y_1': 'y_farthest',\n",
        "                                         'z_1': 'z_farthest'})\n",
        "        \n",
        "    for atom_idx in [0,1]:\n",
        "        df = map_atom_info(df,df_temp, atom_idx)\n",
        "        df = df.rename(columns={'atom_index_farthest': f'atom_index_farthest_{atom_idx}',\n",
        "                                        'distance_farthest': f'distance_farthest_{atom_idx}',\n",
        "                                        'x_farthest': f'x_farthest_{atom_idx}',\n",
        "                                        'y_farthest': f'y_farthest_{atom_idx}',\n",
        "                                        'z_farthest': f'z_farthest_{atom_idx}'})\n",
        "    return df\n",
        "df_test=(get_dist(df_test))    \n",
        "df_train=(get_dist(df_train)) \n",
        "\n",
        "print(df_train.shape, df_test.shape)\n",
        "show_ram_usage()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dt1yQU9hw4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_features(df):\n",
        "    df[\"distance_center0\"]=((df['x_0']-df['c_x'])**2+(df['y_0']-df['c_y'])**2+(df['z_0']-df['c_z'])**2)**(1/2)\n",
        "    df[\"distance_center1\"]=((df['x_1']-df['c_x'])**2+(df['y_1']-df['c_y'])**2+(df['z_1']-df['c_z'])**2)**(1/2)\n",
        "    df[\"distance_c0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n",
        "    df[\"distance_c1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n",
        "    df[\"distance_f0\"]=((df['x_0']-df['x_farthest_0'])**2+(df['y_0']-df['y_farthest_0'])**2+(df['z_0']-df['z_farthest_0'])**2)**(1/2)\n",
        "    df[\"distance_f1\"]=((df['x_1']-df['x_farthest_1'])**2+(df['y_1']-df['y_farthest_1'])**2+(df['z_1']-df['z_farthest_1'])**2)**(1/2)\n",
        "    df[\"vec_center0_x\"]=(df['x_0']-df['c_x'])/(df[\"distance_center0\"]+1e-10)\n",
        "    df[\"vec_center0_y\"]=(df['y_0']-df['c_y'])/(df[\"distance_center0\"]+1e-10)\n",
        "    df[\"vec_center0_z\"]=(df['z_0']-df['c_z'])/(df[\"distance_center0\"]+1e-10)\n",
        "    df[\"vec_center1_x\"]=(df['x_1']-df['c_x'])/(df[\"distance_center1\"]+1e-10)\n",
        "    df[\"vec_center1_y\"]=(df['y_1']-df['c_y'])/(df[\"distance_center1\"]+1e-10)\n",
        "    df[\"vec_center1_z\"]=(df['z_1']-df['c_z'])/(df[\"distance_center1\"]+1e-10)\n",
        "    df[\"vec_c0_x\"]=(df['x_0']-df['x_closest_0'])/(df[\"distance_c0\"]+1e-10)\n",
        "    df[\"vec_c0_y\"]=(df['y_0']-df['y_closest_0'])/(df[\"distance_c0\"]+1e-10)\n",
        "    df[\"vec_c0_z\"]=(df['z_0']-df['z_closest_0'])/(df[\"distance_c0\"]+1e-10)\n",
        "    df[\"vec_c1_x\"]=(df['x_1']-df['x_closest_1'])/(df[\"distance_c1\"]+1e-10)\n",
        "    df[\"vec_c1_y\"]=(df['y_1']-df['y_closest_1'])/(df[\"distance_c1\"]+1e-10)\n",
        "    df[\"vec_c1_z\"]=(df['z_1']-df['z_closest_1'])/(df[\"distance_c1\"]+1e-10)\n",
        "    df[\"vec_f0_x\"]=(df['x_0']-df['x_farthest_0'])/(df[\"distance_f0\"]+1e-10)\n",
        "    df[\"vec_f0_y\"]=(df['y_0']-df['y_farthest_0'])/(df[\"distance_f0\"]+1e-10)\n",
        "    df[\"vec_f0_z\"]=(df['z_0']-df['z_farthest_0'])/(df[\"distance_f0\"]+1e-10)\n",
        "    df[\"vec_f1_x\"]=(df['x_1']-df['x_farthest_1'])/(df[\"distance_f1\"]+1e-10)\n",
        "    df[\"vec_f1_y\"]=(df['y_1']-df['y_farthest_1'])/(df[\"distance_f1\"]+1e-10)\n",
        "    df[\"vec_f1_z\"]=(df['z_1']-df['z_farthest_1'])/(df[\"distance_f1\"]+1e-10)\n",
        "    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"distance\"]\n",
        "    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"distance\"]\n",
        "    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"distance\"]\n",
        "    df[\"cos_c0_c1\"]=df[\"vec_c0_x\"]*df[\"vec_c1_x\"]+df[\"vec_c0_y\"]*df[\"vec_c1_y\"]+df[\"vec_c0_z\"]*df[\"vec_c1_z\"]\n",
        "    df[\"cos_f0_f1\"]=df[\"vec_f0_x\"]*df[\"vec_f1_x\"]+df[\"vec_f0_y\"]*df[\"vec_f1_y\"]+df[\"vec_f0_z\"]*df[\"vec_f1_z\"]\n",
        "    df[\"cos_center0_center1\"]=df[\"vec_center0_x\"]*df[\"vec_center1_x\"]+df[\"vec_center0_y\"]*df[\"vec_center1_y\"]+df[\"vec_center0_z\"]*df[\"vec_center1_z\"]\n",
        "    df[\"cos_c0\"]=df[\"vec_c0_x\"]*df[\"vec_x\"]+df[\"vec_c0_y\"]*df[\"vec_y\"]+df[\"vec_c0_z\"]*df[\"vec_z\"]\n",
        "    df[\"cos_c1\"]=df[\"vec_c1_x\"]*df[\"vec_x\"]+df[\"vec_c1_y\"]*df[\"vec_y\"]+df[\"vec_c1_z\"]*df[\"vec_z\"]\n",
        "    df[\"cos_f0\"]=df[\"vec_f0_x\"]*df[\"vec_x\"]+df[\"vec_f0_y\"]*df[\"vec_y\"]+df[\"vec_f0_z\"]*df[\"vec_z\"]\n",
        "    df[\"cos_f1\"]=df[\"vec_f1_x\"]*df[\"vec_x\"]+df[\"vec_f1_y\"]*df[\"vec_y\"]+df[\"vec_f1_z\"]*df[\"vec_z\"]\n",
        "    df[\"cos_center0\"]=df[\"vec_center0_x\"]*df[\"vec_x\"]+df[\"vec_center0_y\"]*df[\"vec_y\"]+df[\"vec_center0_z\"]*df[\"vec_z\"]\n",
        "    df[\"cos_center1\"]=df[\"vec_center1_x\"]*df[\"vec_x\"]+df[\"vec_center1_y\"]*df[\"vec_y\"]+df[\"vec_center1_z\"]*df[\"vec_z\"]\n",
        "    df=df.drop(['vec_c0_x','vec_c0_y','vec_c0_z','vec_c1_x','vec_c1_y','vec_c1_z',\n",
        "                'vec_f0_x','vec_f0_y','vec_f0_z','vec_f1_x','vec_f1_y','vec_f1_z',\n",
        "                'vec_center0_x','vec_center0_y','vec_center0_z','vec_center1_x','vec_center1_y','vec_center1_z',\n",
        "                'vec_x','vec_y','vec_z'], axis=1)\n",
        "    return df\n",
        "    \n",
        "df_train=add_features(df_train)\n",
        "df_test=add_features(df_test)\n",
        "print(df_train.shape, df_test.shape)\n",
        "show_ram_usage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_l14bu7iAff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_nn_model(input_shape):\n",
        "    inp = Input(shape=(input_shape,))\n",
        "    x = Dense(256)(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(1024)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(1024)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    #x = Dropout(0.4)(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    out1 = Dense(2, activation=\"linear\")(x)#mulliken charge 2\n",
        "    out2 = Dense(6, activation=\"linear\")(x)#tensor 6(xx,yy,zz)\n",
        "    out3 = Dense(12, activation=\"linear\")(x)#tensor 12(others) \n",
        "    x = Dense(128)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(128)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    out = Dense(1, activation=\"linear\")(x)#scalar_coupling_constant    \n",
        "    model = Model(inputs=inp, outputs=[out,out1,out2,out3])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILC9mrx7iJ_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "mol_types=df_train[\"type\"].unique()\n",
        "cv_score=[]\n",
        "cv_score_total=0\n",
        "epoch_n = 400\n",
        "verbose = 0\n",
        "batch_size = 2048\n",
        "    \n",
        "# Set to True if we want to train from scratch. False will reuse saved models as a starting point.\n",
        "retrain =True\n",
        "\n",
        "# Set up GPU preferences\n",
        "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 2} ) \n",
        "config.gpu_options.allow_growth = True\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
        "sess = tf.Session(config=config) \n",
        "K.set_session(sess)\n",
        "\n",
        "start_time=datetime.now()\n",
        "\n",
        "# Loop through each molecule type\n",
        "for mol_type in mol_types:\n",
        "    model_name_rd = ('../keras-neural-net-for-champs/molecule_model_%s.hdf5' % mol_type)\n",
        "    model_name_wrt = ('/kaggle/working/molecule_model_%s.hdf5' % mol_type)\n",
        "    print('Training %s' % mol_type, 'out of', mol_types, '\\n')\n",
        "    \n",
        "    df_train_=df_train[df_train[\"type\"]==mol_type]\n",
        "    df_test_=df_test[df_test[\"type\"]==mol_type]\n",
        "    \n",
        "    # Choose features\n",
        "    input_features=[\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\",\"c_x\",\"c_y\",\"c_z\",\n",
        "                    'x_closest_0','y_closest_0','z_closest_0','x_closest_1','y_closest_1','z_closest_1',\n",
        "                    \"distance\",\"distance_center0\",\"distance_center1\", \"distance_c0\",\"distance_c1\",\"distance_f0\",\"distance_f1\",\n",
        "                    \"cos_c0_c1\",\"cos_f0_f1\",\"cos_center0_center1\",\"cos_c0\",\"cos_c1\",\"cos_f0\",\"cos_f1\",\"cos_center0\",\"cos_center1\",\n",
        "                    \"atom_n\"\n",
        "                   ]\n",
        "    \n",
        "    # Standard Scaler from sklearn does seem to work better here than other Scalers\n",
        "    input_data=StandardScaler().fit_transform(pd.concat([df_train_.loc[:,input_features],df_test_.loc[:,input_features]]))\n",
        "    \n",
        "    target_data=df_train_.loc[:,\"scalar_coupling_constant\"].values\n",
        "    target_data_1=df_train_.loc[:,[\"charge_0\",\"charge_1\"]]\n",
        "    target_data_2=df_train_.loc[:,[\"XX_0\",\"YY_0\",\"ZZ_0\",\"XX_1\",\"YY_1\",\"ZZ_1\"]]\n",
        "    target_data_3=df_train_.loc[:,[\"YX_0\",\"ZX_0\",\"XY_0\",\"ZY_0\",\"XZ_0\",\"YZ_0\",\"YX_1\",\"ZX_1\",\"XY_1\",\"ZY_1\",\"XZ_1\",\"YZ_1\"]]\n",
        "    \n",
        "    #following parameters should be adjusted to control the loss function\n",
        "    #if all parameters are zero, attractors do not work. (-> simple neural network)\n",
        "    m1=1\n",
        "    m2=4\n",
        "    m3=1\n",
        "    target_data_1=m1*(StandardScaler().fit_transform(target_data_1))\n",
        "    target_data_2=m2*(StandardScaler().fit_transform(target_data_2))\n",
        "    target_data_3=m3*(StandardScaler().fit_transform(target_data_3))\n",
        "    \n",
        "    # Simple split to provide us a validation set to do our CV checks with\n",
        "    train_index, cv_index = train_test_split(np.arange(len(df_train_)),random_state=111, test_size=0.1)\n",
        "    \n",
        "    # Split all our input and targets by train and cv indexes\n",
        "    train_input=input_data[train_index]\n",
        "    cv_input=input_data[cv_index]\n",
        "    train_target=target_data[train_index]\n",
        "    cv_target=target_data[cv_index]\n",
        "    train_target_1=target_data_1[train_index]\n",
        "    cv_target_1=target_data_1[cv_index]\n",
        "    train_target_2=target_data_2[train_index]\n",
        "    cv_target_2=target_data_2[cv_index]\n",
        "    train_target_3=target_data_3[train_index]\n",
        "    cv_target_3=target_data_3[cv_index]\n",
        "    test_input=input_data[len(df_train_):,:]\n",
        "\n",
        "    # Build the neural net\n",
        "    nn_model=create_nn_model(train_input.shape[1])\n",
        "    \n",
        "    # If retrain==False, then load a previous saved model as a starting point.\n",
        "    if not retrain:\n",
        "        nn_model = load_model(model_name_rd)\n",
        "        \n",
        "    nn_model.compile(loss='mae', optimizer=Adam())\n",
        "    \n",
        "    # Callback for Early Stopping... May want to raise the min_delta for small numbers of epochs\n",
        "    es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=8,verbose=1, mode='auto', restore_best_weights=True)\n",
        "    # Callback for Reducing the Learning Rate... when the monitor levels out for 'patience' epochs, then the LR is reduced\n",
        "    rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=7, min_lr=1e-6, mode='auto', verbose=1)\n",
        "    # Save the best value of the model for future use\n",
        "    sv_mod = callbacks.ModelCheckpoint(model_name_wrt, monitor='val_loss', save_best_only=True, period=1)  \n",
        "\n",
        "    cv_predict=nn_model.predict(cv_input)\n",
        "    #plot_history(history, mol_type)\n",
        "    \n",
        "    accuracy=np.mean(np.abs(cv_target-cv_predict[0][:,0]))\n",
        "    cv_score.append(np.log(accuracy))\n",
        "    cv_score_total+=np.log(accuracy)\n",
        "    \n",
        "    # Predict on the test data set using our trained model\n",
        "    test_predict=nn_model.predict(test_input)\n",
        "    \n",
        "    # for each molecule type we'll grab the predicted values\n",
        "    test_prediction[df_test[\"type\"]==mol_type]=test_predict[0][:,0]\n",
        "    K.clear_session()\n",
        "\n",
        "cv_score_total/=len(mol_types)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srf3q4bIihqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def submit(predictions):\n",
        "    submit = pd.read_csv('sample_submission.csv')\n",
        "    print(len(submit), len(predictions))   \n",
        "    submit[\"scalar_coupling_constant\"] = predictions\n",
        "    submit.to_csv(\"predictions_test.csv\", index=False)\n",
        "submit(test_prediction)\n",
        "\n",
        "print ('Total training time: ', datetime.now() - start_time)\n",
        "\n",
        "i=0\n",
        "for mol_type in mol_types: \n",
        "    print(mol_type,\": cv score is \",cv_score[i])\n",
        "    i+=1\n",
        "print(\"total cv score is\",cv_score_total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ang5jFEOszVB",
        "colab_type": "text"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaPsiAVmxkbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj_exN-Ns1kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "model = KerasRegressor(build_fn=nn_model)\n",
        "model.fit(x=train_input, y=train_target)\n",
        "\n",
        "perm = PermutationImportance(nn_model, random_state=1).fit(train_input, train_target)\n",
        "eli5.show_weights(perm, feature_names=input_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_qAxZzS1LjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install eli5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_x-1akI1ZWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}